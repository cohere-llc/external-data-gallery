{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28ad107d",
   "metadata": {},
   "source": [
    "The [Zarr project](https://zarr.dev) produces specifications for storing large multi-dimensional arrays. It is particularly useful for cloud storage. [Zarr-Python](https://zarr.readthedocs.io/en/stable/) facilitates working with Zarr arrays from a variety of sources (in-memory, local, cloud). This notebook provides a simple example of using Zarr-Python to access NASA POWER data stored on AWS. We use the experimental caching feature to improve performance (in this case by ~10x).\n",
    "\n",
    "1. Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95344b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zarr\n",
    "from zarr.storage import MemoryStore, FsspecStore\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from zarr.experimental.cache_store import CacheStore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ebec86",
   "metadata": {},
   "source": [
    " 2. Define a remote store and an in-memory store for caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc60ba80",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_store = FsspecStore.from_url(\n",
    "    's3://nasa-power/merra2/spatial/power_merra2_daily_spatial_utc.zarr',\n",
    "    read_only=True,\n",
    "    storage_options={'anon': True}\n",
    "\n",
    ")\n",
    "cache_store = MemoryStore()\n",
    "cached_store = CacheStore(\n",
    "    store=source_store,\n",
    "    cache_store=cache_store,\n",
    "    max_size=256 * 1024 * 1024  # 256 MB cache\n",
    ")\n",
    "group = zarr.open_group(store=cached_store, mode='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9544c5aa",
   "metadata": {},
   "source": [
    "Zarr uses the [`fsspec` package](https://filesystem-spec.readthedocs.io/en/latest/index.html) to interact with a variety of filesystems, including an AWS S3 bucket in this example.\n",
    "\n",
    "We create a store based on a Filesystem Spec pointing to the [NASA POWER S3 bucket on AWS](https://power.larc.nasa.gov/docs/services/aws/), specifying read-only anonymous access as credentials are not required to access this dataset.\n",
    "\n",
    "Next, we create an empty in-memory store, then create a `CacheStore` that will use our in-memory store to cache data from the NASA POWER AWS S3 store as it is accessed. This is useful when repeatedly accessing array chuncks, as in this example.\n",
    "\n",
    "Finally, we open the group of arrays in the NASA POWER collection via our `CacheStore` instance. For details on working with arrays, groups, and stores see the [Zarr User Guide](https://zarr.readthedocs.io/en/stable/user-guide/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40685fd0",
   "metadata": {},
   "source": [
    "3. Examine the group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c418efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list arrays in the group\n",
    "print(\"Arrays in the group:\")\n",
    "for name, array in group.arrays():\n",
    "    print(f\"- {name}: {array.metadata.attributes['long_name']}\")\n",
    "\n",
    "# Get detailed info about a specific array\n",
    "temperature_array = group['T2M']\n",
    "print(f\"T2M definition: {temperature_array.metadata.attributes['definition']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86fbe5b",
   "metadata": {},
   "source": [
    "4. Read locations from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106fae38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "locations = list(csv.DictReader(open('assets/locations.csv')))\n",
    "print(f\"Loaded {len(locations)} locations.\")\n",
    "for loc in locations[:3]:\n",
    "    print(loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59901023",
   "metadata": {},
   "source": [
    "5. Create a function to extract property values for a particular location and date range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd4f3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_property_values(array_name, lat, lon, start_date, end_date):\n",
    "    array = group[array_name]\n",
    "    latitudes = group['lat'][:]\n",
    "    longitudes = group['lon'][:]\n",
    "    times = pd.to_datetime(group['time'][:], unit='D')\n",
    "\n",
    "    lat_idx = (np.abs(latitudes - lat)).argmin()\n",
    "    lon_idx = (np.abs(longitudes - lon)).argmin()\n",
    "\n",
    "    time_mask = (times >= pd.to_datetime(start_date)) & (times <= pd.to_datetime(end_date))\n",
    "    time_indices = np.where(time_mask)[0]\n",
    "    selected_times = times[time_mask]\n",
    "\n",
    "    values = array[time_indices, lat_idx, lon_idx]\n",
    "\n",
    "    units = array.attrs.get('units', 'unknown')\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        'date': selected_times,\n",
    "        array_name: values,\n",
    "        'units': units\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66a28ea",
   "metadata": {},
   "source": [
    "Zarr array data is accessed with NumPy-like syntax. Accessing slices of array data for different locations, as done in this function, would likely result in repeatedly reading data from the same array chunks. By setting up a cache store (see above), we can reduce the number of times data need to be transferred from the remote store."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe7694a",
   "metadata": {},
   "source": [
    "6. Extract average temperatures for each location for one year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8fad24",
   "metadata": {},
   "outputs": [],
   "source": [
    "for location in locations:\n",
    "    lat = float(location['lat'])\n",
    "    lon = float(location['lon'])\n",
    "    df = extract_property_values('T2M', lat, lon, '2009-01-01', '2009-12-31')\n",
    "    avg_temp = df['T2M'].mean()\n",
    "    print(f\"Average temperature in 2009 for (lat: {lat}, lon: {lon}): {avg_temp:.2f} {df['units'].iloc[0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "external-data-gallery (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
