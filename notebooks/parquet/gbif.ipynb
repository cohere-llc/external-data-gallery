{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3e6c912",
   "metadata": {},
   "source": [
    "# Parquet Example: GBIF Occurrence Data on AWS\n",
    "\n",
    "[Apache Parquet](https://parquet.apache.org) is a column-based file format. [Dask](https://docs.dask.org/en/stable/) is a Python package for parallel computation. This example uses a Dask Dataframe to interact with Parquet data from the the [Global Biodiversity Information Facility (GBIF) Species Occurrences dataset on AWS](https://aws.amazon.com/marketplace/pp/prodview-dvyemtksskta2?sr=0-1&ref_=beagle&applicationId=AWSMPContessa#resources). Details on using Dask Dataframes with Parquet data can be found [here](https://docs.dask.org/en/latest/dataframe-parquet.html).\n",
    "\n",
    "1. Load dependencies and set up Dask to use a multithreading scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825a16de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import dask.dataframe as dd\n",
    "\n",
    "\n",
    "dask.config.set(scheduler='threads')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5da99b",
   "metadata": {},
   "source": [
    "2. Create a DataFrame for AWS GBIF occurrence data for June 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd3370c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dd.read_parquet(\n",
    "    \"s3://gbif-open-data-af-south-1/occurrence/2021-06-01/occurrence.parquet/\",\n",
    "    storage_options={\"anon\": True},\n",
    "    engine=\"pyarrow\",\n",
    "    parquet_file_extension=\"\"\n",
    ")\n",
    "print(f\"Number of partitions: {df.npartitions}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4778eb8f",
   "metadata": {},
   "source": [
    "3. Count the number of occurrences by country\n",
    "\n",
    "(This takes several minutes to run.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90398232",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_df = df[['countrycode', 'specieskey']] \\\n",
    "    .groupby(['countrycode']) \\\n",
    "    .size() \\\n",
    "    .compute() \\\n",
    "    .sort_values(ascending=False)\n",
    "\n",
    "print(reduced_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0ef633",
   "metadata": {},
   "source": [
    "The Dask `DataFrame` has the same API as Pandas DataFrames. Read more about them [here](https://docs.dask.org/en/stable/dataframe.html) and see example scripts [here](https://examples.dask.org/dataframe.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "external-data-gallery (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
